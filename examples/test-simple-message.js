/**
 * Script pour tester une requ√™te simple et afficher clairement le message
 * dans le terminal.
 *
 * Usage:
 * 1. Configurer les variables d'environnement (TEST_API_KEY, API_BASE_URL si non localhost:3000)
 * 2. D√©marrer le serveur: npm run dev
 * 3. Ex√©cuter: node examples/test-simple-message.js
 */

import axios from 'axios';
import dotenv from 'dotenv';

dotenv.config();

const API_BASE_URL = process.env.API_BASE_URL || 'http://localhost:3000';
const API_KEY = process.env.TEST_API_KEY || 'test-api-key-123';

// Configuration axios pour la Gateway
const api = axios.create({
  baseURL: API_BASE_URL,
  headers: {
    'X-API-Key': API_KEY,
    'Content-Type': 'application/json'
  },
  timeout: 30000 // 30 secondes de timeout
});

/**
 * Envoie une requ√™te simple et affiche le message dans le terminal
 */
async function testAndDisplayMessage(prompt = 'Ecrit le 5e amendement', model = 'gpt-4o') {
  console.log(`üöÄ Envoi d'une requ√™te au mod√®le ${model} avec le prompt: "${prompt}"`);
  console.log(`üîë Utilisation de l'API: ${API_BASE_URL} avec la cl√©: ${API_KEY ? API_KEY.substring(0, 10) + '...' : 'Non d√©finie'}`);
  
  try {
    // V√©rifier si la cl√© API est d√©finie
    if (!API_KEY) {
      console.error('‚ùå TEST_API_KEY n\'est pas d√©finie dans les variables d\'environnement.');
      return;
    }

    console.log('‚è≥ Requ√™te en mode streaming en cours...');
    
    const response = await api.post('/v1/chat/completions', {
      model: model,
      messages: [
        { role: 'user', content: prompt }
      ],
      max_tokens: 200,
      stream: true  // Activer le mode streaming
    }, {
      responseType: 'stream'  // Important pour qu'axios g√®re la r√©ponse comme un stream
    });
    
    console.log('‚úÖ Connexion √©tablie, r√©ception du stream:\n');
    
    // Afficher l'en-t√™te du message
    console.log('üìù D√âBUT DU MESSAGE üìù');
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    
    // Variables pour reconstruire la r√©ponse compl√®te
    let fullContent = '';
    let buffer = '';
    let usageInfo = null;
    let modelInfo = null;
    let errorOccurred = false;
    
    // Traiter le stream de donn√©es
    response.data.on('data', (chunk) => {
      buffer += chunk.toString();
      
      // Traiter les lignes compl√®tes dans le buffer
      const lines = buffer.split('\n');
      buffer = lines.pop() || ''; // Garder la derni√®re ligne incompl√®te
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6).trim();
          
          // V√©rifier si c'est la fin du stream
          if (data === '[DONE]') {
            return;
          }
          
          try {
            const parsed = JSON.parse(data);
            
            // Extraire le mod√®le s'il est pr√©sent
            if (parsed.model && !modelInfo) {
              modelInfo = parsed.model;
            }
            
            // Extraire les statistiques d'utilisation si pr√©sentes
            if (parsed.usage) {
              usageInfo = parsed.usage;
            }
            
            // Extraire et afficher le contenu
            if (parsed.choices && parsed.choices[0] && parsed.choices[0].delta && parsed.choices[0].delta.content) {
              const content = parsed.choices[0].delta.content;
              process.stdout.write(content);
              //Afficher un saut de ligne pour chaque chunk
                console.log();
              fullContent += content;
            }
          } catch (e) {
            // Ignorer les erreurs de parsing pour les lignes non-JSON
          }
        }
      }
    });
    
    // G√©rer la fin du stream
    response.data.on('end', () => {
      if (errorOccurred) return;
      
      // Afficher la fin du message
      console.log('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log('üìù FIN DU MESSAGE üìù\n');
      
      // Afficher les statistiques d'utilisation si disponibles
      if (usageInfo) {
        console.log('üìä Statistiques d\'utilisation:');
        console.log(`   - Tokens prompt: ${usageInfo.prompt_tokens}`);
        console.log(`   - Tokens r√©ponse: ${usageInfo.completion_tokens}`);
        console.log(`   - Tokens total: ${usageInfo.total_tokens}`);
      }
      
      // Afficher le mod√®le utilis√©
      console.log(`ü§ñ Mod√®le utilis√©: ${modelInfo || model}`);
    });
    
    // G√©rer les erreurs du stream
    response.data.on('error', (err) => {
      errorOccurred = true;
      console.error('\n‚ùå Erreur durant le streaming:', err.message);
    });
    
    // Retourner une promesse qui se r√©sout lorsque le stream est termin√©
    return new Promise((resolve, reject) => {
      response.data.on('end', resolve);
      response.data.on('error', reject);
    });

  } catch (error) {
    console.error('‚ùå La requ√™te a √©chou√©:');
    if (error.response) {
      // Erreur de l'API (e.g., 4xx, 5xx)
      console.error(`   Status: ${error.response.status}`);
      console.error(`   Message: ${JSON.stringify(error.response.data, null, 2)}`);
    } else if (error.request) {
      // La requ√™te a √©t√© faite mais aucune r√©ponse n'a √©t√© re√ßue
      console.error(`   Aucune r√©ponse re√ßue: ${error.message}`);
    } else {
      // Probl√®me lors de la configuration de la requ√™te
      console.error(`   Erreur lors de la configuration de la requ√™te: ${error.message}`);
    }
  }
}

// Si ce fichier est ex√©cut√© directement
if (import.meta.url === `file://${process.argv[1]}`) {
  // R√©cup√©rer les arguments optionnels
  const prompt = process.argv[2] || 'Ecrit le 5e amendement';
  const model = process.argv[3] || 'gpt-4o';
  
  console.log('üß™ Test de messagerie simple LLM API Gateway\n');
  
  testAndDisplayMessage(prompt, model).catch(console.error);
}

export {
  testAndDisplayMessage
};
